# **Week 1: Sentiment Analysis Project**

## **Introduction:**
Welcome to **Week 1** of our **Sentiment Analysis** project! In this project, we aim to analyze the sentiment of text data using **Machine Learning (ML)** techniques. This README will guide you through the essential terminologies, tools, and libraries we'll be using, including **Jupyter/Colab notebook** environments, **NumPy**, and **Pandas**.

## **Terminologies:**
1. **Sentiment Analysis**: Also known as opinion mining, it involves using natural language processing and text analysis techniques to determine the sentiment expressed in a piece of text.
2. **Machine Learning (ML)**: A subset of artificial intelligence that focuses on the development of algorithms allowing computers to learn and make predictions from data.
3. **Jupyter/Colab Notebook**: Interactive computing environments that allow you to create and share documents containing live code, equations, visualizations, and narrative text.
4. **NumPy**: A powerful Python library used for numerical computing. It provides support for arrays, matrices, and a collection of mathematical functions to operate on these arrays.
5. **Pandas**: A Python library widely used for data manipulation and analysis. It offers data structures and functions to efficiently work with structured data.

## **Tools and Libraries:**
1. **Jupyter/Colab Notebook**: We'll be using Jupyter or Google Colab notebooks to write and execute our code interactively. These notebooks provide a convenient environment for experimentation and collaboration.
2. **NumPy**: We'll leverage NumPy for numerical computations, especially for handling arrays and matrices efficiently.
3. **Pandas**: Pandas will be used extensively for data manipulation, including loading, cleaning, and transforming our dataset.

## **Getting Started:**
**Setting Up Environment**:
   - If you haven't already, install Jupyter Notebook or set up a Google Colab account.
   - Ensure NumPy and Pandas are installed in your Python environment. You can install them using pip:
     ```
     pip install numpy pandas
     ```
# **Week 2: Data Pre-processing and Visualization**

### **Resources:**
1. **Matplotlib for Beginners**: [Watch Video](https://www.youtube.com/watch?v=OZOOLe2imFo)
2. **Splitting into Training and Testing Datasets**: [Watch Video](https://www.youtube.com/watch?v=BUkqYGPnLZ8)
3. **Normalization Techniques**: [Watch Video](https://www.youtube.com/watch?v=jMvlyoegui4)
4. **Normalization using sklearn**: [Watch Video](https://www.youtube.com/watch?v=ZddUwo4R5ug)
5. **Feature Selection**:
   - [Watch Video](https://www.youtube.com/watch?v=EqLBAmtKMnQ)
   - [Read Article](https://medium.com/geekculture/feature-selection-in-machine-learning-correlation-matrix-univariate-testing-rfecv-1186168fac12)

### **Tasks:**
1. **Data Pre-processing**: Learn how to clean and prepare your data for analysis.
2. **Data Visualization**: Use Matplotlib to visualize your data.
3. **Splitting Data**: Understand how to split your data into training and testing sets.
4. **Normalization**: Learn and apply normalization techniques to your data.
5. **Feature Selection**: Explore and apply feature selection methods.

# **Week 3: Machine Learning Algorithms**

### **Resources:**
1. **Linear Regression**: [Watch Playlist](https://www.youtube.com/playlist?list=PLfFghEzKVmjsxY5ciwh27IyxuFymb798X)
2. **Logistic Regression**: [Watch Playlist](https://www.youtube.com/playlist?list=PLfFghEzKVmjsF8ixJ-xKVuQayPWRH4Sp6)
3. **Support Vector Machine**: [Watch First 4 Videos](https://www.youtube.com/watch?v=dAxxUfmvG2I&list=PLfFghEzKVmjvzS4DILijsdQk27Ew7xIPu&index=5)
4. **K-Nearest Neighbour**: [Watch Video](https://www.youtube.com/watch?v=wKmEULDRszo)

### **Tasks:**
1. **Implement Algorithms**: Learn and implement the following algorithms using sklearn:
   - Linear Regression
   - Logistic Regression
   - Support Vector Machine (SVM)
   - K-Nearest Neighbour (KNN)
2. **Using fit() and predict() Methods**: Explore how to use these methods in sklearn. Usually, it involves only a few lines of code.

### **Classification Metrics:**
1. **Accuracy, Precision, Recall**: [Read Article](https://www.evidentlyai.com/classification-metrics/accuracy-precision-recall#:~:text=Accuracy%20is%20a%20metric%20that,often%20the%20model%20is%20right%3F)
2. **Confusion Matrix**: [Read Article](https://www.evidentlyai.com/classification-metrics/confusion-matrix)
3. **F1 Score**: [Read Article](https://encord.com/blog/f1-score-in-machine-learning/#:~:text=A%20high%20F1%20score%20generally,has%20trouble%20striking%20that%20balance.)
4. **R-Squared in Regression Analysis**: [Read Article](https://www.geeksforgeeks.org/ml-r-squared-in-regression-analysis/)

#  Week 4: Deep Learning

### Coursera Course Link
- [Neural Networks and Deep Learning](https://www.coursera.org/learn/neural-networks-deep-learning?&utm_medium=sem&utm_source=gg&utm_campaign=b2c_india_neural-networks-deep-learning_deeplearning.ai_ftcof_learn_arte_may-24_dr_sem_rsa_gads_lg-all&campaignid=21254051965&adgroupid=160484001823&device=c&keyword=neural%20networks%20and%20deep%20learning%20coursera&matchtype=b&network=g&devicemodel=&adposition=&creativeid=698134896937&hide_mobile_promo&gad_source=1&gclid=CjwKCAjwrvyxBhAbEiwAEg_KgskaJJSweYGV4Z5HBC4LXg4F6XC0bBYRJUEkHRDOKwEBWpjG7sPsRxoCYGoQAvD_BwE)

### GitHub Repository
- [Coursera Deep Learning Specialization](https://github.com/amanchadha/coursera-deep-learning-specialization/tree/master/C1%20-%20Neural%20Networks%20and%20Deep%20Learning)

### Instructions
1. Click on "Audit course" on the Coursera course page.
2. Click on "Skip" to bypass any payment options.

### Assignments and Quizzes
- Review all assignments and quizzes available in the [GitHub repository](https://github.com/amanchadha/coursera-deep-learning-specialization/tree/master/C1%20-%20Neural%20Networks%20and%20Deep%20Learning).

### Weekly Summary Assignment
- Write a report/summary (not more than 150 words) of what you learned in this week.
- Submit the PDF file of the summary on Teams before the deadline.

# Week 5: Natural Language Processing (NLP) Resources

Welcome to Week 5 of our NLP course! This week, we will dive into various essential concepts and techniques in Natural Language Processing.

## Resources

### 1. Why NLP?
Understand the importance and applications of NLP.
- [Why NLP?](https://www.youtube.com/watch?v=CMrHM8a3hqw)

### 2. Reading from and Writing to a File
Learn how to handle file operations in Python.
- [Reading from and writing to a file](https://www.youtube.com/watch?v=-CogPevWFRU)

### 3. Regular Expressions (Regex)
Explore regular expressions to handle pattern matching in text.
- **Cheat sheet**: [Regex Cheat Sheet](https://ihateregex.io/cheatsheet)
- **Notebook**: [Regex Notebook](https://drive.google.com/file/d/1789aqdy4Jiq-L2zEKYJC2EKiLlraYCpL/view?usp=sharing)
- **Additional Resources**: Explore more on the internet.

### 4. Stemming and Lemmatization
Understand the techniques to reduce words to their root forms.
- [Stemming and Lemmatization](https://www.youtube.com/watch?v=HHAilAC3cXw)

### 5. Stop Words
Learn about stop words and how to handle them in NLP tasks.
- [Stop words](https://www.youtube.com/watch?v=vUPAOU2NPls)

### 6. Part of Speech Tagging and Named Entity Recognition (NER)
Learn how to tag parts of speech and recognize named entities in text.
- [Part of Speech Tagging and NER - Video 1](https://www.youtube.com/watch?v=gdHWoQWZGkk&pp=ygU5UGFydCBvZiBzcGVlY2ggdGFnZ2luZyBhbmQgTmFtZWQgRW50aXR5IFJlY29nbml0aW9uIChORVIp)
- [Part of Speech Tagging and NER - Video 2](https://www.youtube.com/watch?v=2XUhKpH0p4M)

## Instructions
1. Watch the videos in the order provided to build a solid understanding of each topic.
2. Explore the Regex cheat sheet and notebook to get hands-on experience with regular expressions.
3. Practice the concepts learned by implementing them in small projects or exercises.
4. Feel free to explore additional resources on the internet for more in-depth knowledge.

# Sentiment Analysis SOC: Final Project

## Overview
This project involves performing sentiment analysis on the IMDB Dataset of 50K Movie Reviews. The task is to classify movie reviews as positive or negative using various NLP techniques and models.

## Deliverables
- A Python notebook (.ipynb file) or a Python (.py) file containing all the code for this project.

## Dataset
- [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)

## Project Structure
The project is divided into three phases:

### Phase 1: Text Embeddings
1. **Introduction to Text Embeddings**: Watch the video on text embeddings:
   - [What are text embeddings?](https://www.youtube.com/watch?v=sNa_uiqSlJo&list=PLz-ep5RbHosU2hnz5ejezwaYpdMutMVB0&index=11)
2. **Hugging Face**: Create an account on Hugging Face.
   - [Hugging Face](https://huggingface.co/)
3. **Generate Access Token**:
   - Go to your profile, click on Settings, then Access Tokens, and create a new token. Copy the key (HF_TOKEN).
4. **Using Text Embeddings**:
   - Follow the example in this [notebook](https://colab.research.google.com/drive/1onJbU686qqjsFMFFasG_IY2-quxs9IZs?usp=drive_link) to understand how to use text embeddings.
5. **Calculate Accuracy**:
   - Use the text embeddings to calculate the accuracy of your model.

### Phase 2: TF-IDF and Machine Learning Models
1. **Data Splitting**: Split the dataset into training and testing sets.
2. **TF-IDF**: Convert words to numerical representation using TF-IDF.
3. **ML Models**: Use any three ML models from sklearn to classify the reviews. Report the best accuracy obtained.

### Phase 3: Neural Network
1. **Feed-Forward Neural Network**: Train a feed-forward neural network using TensorFlow or PyTorch.
2. **Binary Classification**: Use TF-IDF for the binary classification task.
3. **Model Evaluation**: Report the accuracy, check for overfitting, and implement strategies to prevent overfitting and improve test accuracy if necessary.

## Steps
1. **Load and Explore the Dataset**:
   - Show how the dataset looks.
   - Display one positive and one negative review.
   - Plot a graph showing the distribution of positive and negative reviews.

2. **Phase 1**:
   - Follow the instructions to use text embeddings from Hugging Face.
   - Calculate and report the accuracy.

3. **Phase 2**:
   - Split the data.
   - Apply TF-IDF.
   - Train three ML models and report their accuracies.

4. **Phase 3**:
   - Train a feed-forward neural network.
   - Evaluate the model.
   - Address overfitting and improve accuracy.

## Usage
1. Clone the repository.
2. Ensure you have the necessary libraries installed.
3. Run the notebook or Python script to perform the analysis.

## Dependencies
- Python 3.x
- Libraries: pandas, numpy, matplotlib, seaborn, sklearn, tensorflow/pytorch, transformers, huggingface_hub

## Contact
For any queries, feel free to reach out to me. Use ChatGPT or other resources if you face any difficulties during the implementation.

**Happy coding!**



